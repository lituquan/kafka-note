
### 1.kafka三个特性
        mq
        容错持久化
        准实时流处理

### 2.kafka的概念
        cluster
            broker
                topic

        topic
            partition
                replication

        record
            offset
                    
### 3.api
    producer
        负载均衡-->选择分区-->先push到分区leader-->follow ack-->leader ack

    备注：
        在消息发送的过程中,涉及到了两个线程——main 线程和 Sender 线程。在 main 线程中创建了一个双端队列 RecordAccumulator。main 线程将消息发送给 RecordAccumulator,Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka Broker。

    consumer
        消费者组：
            组内互斥，同一个组不能处理同一个分区。
        高级api

        低级api:
            可以指定topic\offset\partition

    stream
    connector

### 4.使用场景
    消息
    存储
    流处理
	
### 5.kafka结构

	producer-->kafka-->consumer
				|
				|
			zookeeper
			

    kafka 是一个cluster,有多个broker(server节点)组成。
		每个broker中有多个Topic
    Topic 如果有多于一个partition,
	    partition会有多个replication,分布在不同Broker中。
	replication是分角色的,leader和follower。
		partition 是一个队列。

    消费消息定位<topic,partition,offset>

### 6.ISR 机制
    https://cloud.tencent.com/developer/article/1595175

    高可用,kafka做了副本冗余,Leader 副本提供对外读写,Follow 副本只是同步数据。会出现远远落后的副本和可用同步副本,
    也就是In-Sync Replication：ISR,同步副本集合。follower副本与leader副本不同步的原因：
        (1)同步数据请求速度追不上：follower副本在一段时间无法追上leader副本端的消息接收速度。比如follower副本的网络I/O阻塞,这会导致follower副本同步leader副本的速度大大降低。
        (2)进程卡住：follower副本一段时间无法向leader发出请求,比如follower频繁的进行GC
        (3)新创建的副本：用户主动增加副本数,新创建的副本在启动后会追赶leader的进度,这段时间新增的follower副本通常与leader副本是不同步的

    存储：ISR服务通过Zookeeper维护,ISR中的副本会被剔除,也会有新增。
        一个分区的所有副本集合叫做 AR（ Assigned Repllicas ）
        与 leader-replica 未能保持同步的副本集叫做 OSR（ Out-Sync Relipcas ）
        因此我们就能得到这么一个表示：AR = ISR + OSR,翻译一下就是一个分区的副本集分为同步集合和非同步集合两部分。
	
    踢出：
        如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参数设定，默认30s。

### 7.生产者
#### 生产者如何提高吞吐
    batch.size：批次大小，默认16k
    linger.ms：等待时间，修改为5-100ms
    compression.type：压缩snappy
    RecordAccumulator：缓冲区大小，修改为64m	
				
#### 数据可靠性--ack机制
    acks:
        0 发出即可
        1 收到leader的ack
        -1 all 需要leader+ISR的ack                

    数据完全可靠条件 = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2

    数据重复：leader切换，ISR中写入的数据，由于客户端没有ack，再发了一次。

#### 幂等
    幂等性就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。
    精确一次（Exactly Once） = 幂等性 + 至少一次（ ack=-1 + 分区副本数>=2 + ISR最小副本数量>=2） 。

    重复数据的判断标准：具有 <PID, Partition, SeqNumber> 相同主键的消息提交时，Broker只会持久化一条。其中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。

    所以幂等性只能保证的是在单分区单会话内不重复。

#### 数据语义
    至少一次（At Least Once）= ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2。【产生重复】
    最多一次（At Most Once）= ACK级别设置为0【丢失数据】

    精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。Kafka 0.11版本以后，引入了一项重大特性：幂等性和事务。

#### 事务
    kafka支持事务

#### 数据有序
    单分区有序

